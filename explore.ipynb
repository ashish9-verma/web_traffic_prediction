{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "import datetime\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import operator\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('./key_trunc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./sample_submission_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt = pd.read_csv(\"train_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-dea6371ed687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3745\u001b[0;31m                     \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3746\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   3284\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3286\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train[col] = pd.to_numeric(train[col],downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).median()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).mean()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_std(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).std()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_min(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).min()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).max()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_overall(row):\n",
    "    return pd.Series(pd.Series(row)[1:].mean()).repeat(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_overall(row):\n",
    "    return pd.Series(pd.Series(row)[1:].median()).repeat(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mean_diff(row, last_n_days):\n",
    "#     return pd.Series(pd.rolling_mean(np.diff(pd.Series(row)), window = last_n_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_last_day_visits(row):\n",
    "#     return row[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_long_stats(func_type, df, df_melt, last_n_days = None):\n",
    "\n",
    "    if func_type == \"median\":\n",
    "        rolling_stats = df.apply(get_median, last_n_days = last_n_days, axis = 1)\n",
    "        \n",
    "    elif func_type == \"mean\":\n",
    "        rolling_stats = df.apply(get_mean, last_n_days = last_n_days, axis = 1)\n",
    "    \n",
    "    elif func_type == \"std\":\n",
    "        rolling_stats = df.apply(get_std, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"min\":\n",
    "        rolling_stats = df.apply(get_min, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"max\":\n",
    "        rolling_stats = df.apply(get_max, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"mean_overall\":\n",
    "        rolling_stats = df.apply(get_mean_overall, axis = 1)\n",
    "\n",
    "    elif func_type == \"median_overall\":\n",
    "        rolling_stats = df.apply(get_median_overall, axis = 1)\n",
    "\n",
    "#     elif func_type == \"mean_diff\":\n",
    "#         rolling_stats = df.iloc[:, -61:].progress_apply(get_mean_diff, last_n_days = last_n_days, axis = 1)\n",
    "        \n",
    "#     elif func_type == \"last_day_visits\":        \n",
    "#         rolling_stats = df.iloc[:, -61:].progress_apply(get_last_day_visits, axis = 1)\n",
    "    \n",
    "    rolling_stats_df = pd.concat([df.Page, rolling_stats.apply(pd.Series)], axis = 1)  \n",
    "    rolling_stats_df.columns = [\"Page\"] + list(df.columns[-60:])\n",
    "    \n",
    "    rolling_stats_df = pd.melt(rolling_stats_df, id_vars=['Page'], var_name=\"date\", value_name=func_type + \"_\" + str(last_n_days))        \n",
    "    \n",
    "    df_melt = pd.merge(df_melt, rolling_stats_df, on = [\"Page\", \"date\"])     \n",
    "    \n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_melt(train):\n",
    "    \n",
    "#     train_melt = pd.read_csv(\"train_feats.csv\")\n",
    "        \n",
    "#     Commented because these features are already generated\n",
    "    train_melt = pd.melt(pd.concat([train.Page, \n",
    "                                    train.iloc[:, -60:]],\n",
    "                                    axis = 1),\n",
    "                                    id_vars=['Page'], \n",
    "                                    var_name=\"date\", value_name=\"visits\")\n",
    "\n",
    "#     train_melt = get_long_stats(\"mean\", train, train_melt, 7)\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "#     train_melt = get_long_stats(\"median\", train, train_melt, 7)\n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"mean_overall\", train, train_melt, 60)\n",
    "    train_melt = get_long_stats(\"median_overall\", train, train_melt, 60)\n",
    "    print train_melt.head()\n",
    "    \n",
    "#     train_melt = get_long_stats(\"mean_diff\", train, train_melt, 7)\n",
    "#     train_melt = get_long_stats(\"last_day_visits\", train, train_melt)\n",
    "    \n",
    "    train_melt[\"date_num\"] = train_melt.apply(get_date, axis = 1)\n",
    "    train_melt[\"weekday\"] = train_melt.apply(get_weekday, axis = 1)\n",
    "    \n",
    "    # Columns i am not using\n",
    "    # train_melt[\"month\"] = train_melt.progress_apply(get_month, axis = 1)\n",
    "\n",
    "    return train_melt \n",
    "\n",
    "def get_lang_features(train_melt):\n",
    "    \n",
    "    train_melt = pd.merge(train_melt, pd.concat([train.Page, train.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    train_melt.columns = ['Page', 'date', 'visits', 'mean_30', 'mean_60', 'median_30', 'median_60', 'std_30', 'std_60', 'min_30', 'min_60', 'max_30', 'max_60', 'mean_overall', 'median_overall', 'date_num', 'weekday', 'language']\n",
    "    \n",
    "    lang_date_melt = train_melt[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\", \"min_30\", \"min_60\", \"max_30\", \"max_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "\n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\", \"lang_min_30_mean\", \"lang_min_60_mean\", \"lang_max_30_mean\", \"lang_max_60_mean\"]\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return train_melt\n",
    "\n",
    "def get_weekday_features(train_melt):\n",
    "    \n",
    "    weekday_page_melt = train_melt[[\"weekday\", \"Page\", \"visits\"]]\n",
    "    \n",
    "    weekday_feats = pd.DataFrame(weekday_page_melt.groupby([\"weekday\", \"Page\"], as_index = False).aggregate(np.mean))\n",
    "\n",
    "    weekday_feats.columns = [\"weekday\", \"Page\", \"weekday_mean_visits\"]\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, weekday_feats, on = [\"weekday\", \"Page\"])\n",
    "    \n",
    "    return train_melt\n",
    "    \n",
    "train_melt = generate_train_melt(train)\n",
    "train_melt = get_lang_features(train_melt)\n",
    "train_melt = get_weekday_features(train_melt)\n",
    "train_melt.to_csv(\"train_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_source(row):\n",
    "    return row.Page.split[\".\"][-1].split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language(row):\n",
    "    try:\n",
    "        return row.Page.split(\".\")[0].split(\"_\")[-1]    \n",
    "    except:\n",
    "        return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month(row):\n",
    "    return row.date.split(\"-\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(row):\n",
    "    return row.date.split(\"-\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weekday(row):\n",
    "    return datetime.datetime.strptime(row.date, '%Y-%m-%d').date().weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_language_mean(row):\n",
    "# lang_count = pd.Series(train_melt.groupby([\"language\"])[\"Page\"].count()).sort_values(axis = 0, ascending = False)\n",
    "# print lang_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_test(row, last_index, last_n_days, pred_index):\n",
    "    \n",
    "    start_loc = max(min(last_index - last_n_days, pred_index), 0)\n",
    "    end_loc = min(last_index, pred_index)\n",
    "\n",
    "    if start_loc < end_loc:\n",
    "        return np.median(row.iloc[ start_loc : end_loc ].tolist())\n",
    "    else:\n",
    "        return np.median(row.iloc[ pred_index - last_n_days : pred_index ].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_test(row, last_index, last_n_days, pred_index):\n",
    "    \n",
    "    start_loc = max(min(last_index - last_n_days, pred_index), 0)\n",
    "    end_loc = min(last_index, pred_index)\n",
    "    \n",
    "    if start_loc < end_loc:\n",
    "        return np.mean(row.iloc[start_loc : end_loc].tolist())\n",
    "    else:\n",
    "        return np.mean(row.iloc[pred_index - last_n_days : pred_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mean_diff_test(row, last_index):\n",
    "    \n",
    "#     start_loc = min(last_index - 7, 61)\n",
    "#     end_loc = min(last_index, 61)\n",
    "    \n",
    "#     if start_loc < end_loc:\n",
    "#         return np.mean([int(x) for x in np.diff( row.iloc[start_loc : end_loc] ) ], dtype=None)\n",
    "#     else:\n",
    "#         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lang_features_test(test_df):\n",
    "    \n",
    "    test_df = pd.merge(test_df, pd.concat([overall_df.Page, overall_df.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    test_df.columns = ['Page', 'date', 'visits', 'mean_30', 'mean_60', 'median_30', 'median_60', 'std_30', 'std_60', 'min_30', 'min_60', 'max_30', 'max_60', 'mean_overall', 'median_overall', 'date_num', 'weekday', 'language']\n",
    "    \n",
    "    lang_date_melt = test_df[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\", \"min_30\", \"min_60\", \"max_30\", \"max_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\", \"lang_min_30_mean\", \"lang_min_60_mean\", \"lang_max_30_mean\", \"lang_max_60_mean\"]\n",
    "        \n",
    "    test_df = pd.merge(test_df, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_last_day_visits_test(row, last_index):\n",
    "    \n",
    "#     return row.iloc[last_index - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "        \n",
    "    y_true = y_true.get_label()\n",
    "    y_pred = np.array(y_pred)\n",
    "        \n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "\n",
    "    return \"smape\", np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(train, label_train, valid = None, label_valid = None):\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'reg:linear'\n",
    "    params['eta'] = 0.05\n",
    "    params['max_depth'] = 7\n",
    "    params['silent'] = 1\n",
    "    params['min_child_weight'] = 0\n",
    "    params['subsample'] = 1\n",
    "    params['colsample_bytree'] = 1\n",
    "    params['nthread'] = 13\n",
    "    params['gamma'] = 0\n",
    "    params['max_delta_step'] = 0\n",
    "    \n",
    "    d_train = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    if valid is not None:\n",
    "        d_valid = xgb.DMatrix(valid, label=label_valid)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'validation')]\n",
    "    else:\n",
    "        watchlist = [(d_train, 'train')]\n",
    "        \n",
    "    bst = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=10, verbose_eval=10, feval=smape, maximize = False)\n",
    "\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_train_melt = np.log1p(train_melt[\"visits\"])\n",
    "label_train_melt = train_melt[\"visits\"]\n",
    "# label_train_melt = boxcox(np.array(label_train_melt), lmbda=0.094) #lambda found from default boxcox on outlier-stripped data\n",
    "\n",
    "# label_train_melt = [0] + np.diff(train_melt[\"visits\"]).tolist()\n",
    "\n",
    "train_melt.drop(\"visits\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"date\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"language\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"Page\", axis = 1, inplace = True)\n",
    "\n",
    "# train_melt.drop(\"last_day_visits_None\", axis = 1, inplace = True)\n",
    "# train_melt.drop(\"mean_diff_7\", axis = 1, inplace = True)\n",
    "\n",
    "# train_melt.drop(\"mean_7\", axis = 1, inplace = True)\n",
    "# train_melt.drop(\"median_7\", axis = 1, inplace = True)\n",
    "\n",
    "train_melt.date_num = pd.to_numeric(train_melt.date_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:77660.7\tvalidation-rmse:83728.1\ttrain-smape:164.809\tvalidation-smape:164.101\n",
      "Multiple eval metrics have been passed: 'validation-smape' will be used for early stopping.\n",
      "\n",
      "Will train until validation-smape hasn't improved in 10 rounds.\n",
      "[10]\ttrain-rmse:62404.2\tvalidation-rmse:67756.6\ttrain-smape:76.4949\tvalidation-smape:76.7528\n",
      "[20]\ttrain-rmse:55736.5\tvalidation-rmse:60716.2\ttrain-smape:54.918\tvalidation-smape:55.0368\n",
      "[30]\ttrain-rmse:53041.6\tvalidation-rmse:57806.8\ttrain-smape:49.0655\tvalidation-smape:49.4274\n",
      "[40]\ttrain-rmse:51934.1\tvalidation-rmse:56554.4\ttrain-smape:49.0367\tvalidation-smape:49.2167\n",
      "Stopping. Best iteration:\n",
      "[36]\ttrain-rmse:52271.6\tvalidation-rmse:56971\ttrain-smape:48.1202\tvalidation-smape:48.6739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, label_train, label_valid = train_test_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "bst = run_xgb(x_train, label_train, x_valid, label_valid)\n",
    "\n",
    "# bst = run_xgb(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature    fscore\n",
      "0   lang_median_60_mean  0.010996\n",
      "1               mean_60  0.011996\n",
      "2      lang_min_60_mean  0.012329\n",
      "3                min_60  0.016328\n",
      "4      lang_min_30_mean  0.016328\n",
      "5     lang_mean_30_mean  0.017328\n",
      "6               weekday  0.022992\n",
      "7   lang_median_30_mean  0.023992\n",
      "8      lang_max_30_mean  0.029990\n",
      "9             median_60  0.030656\n",
      "10     lang_max_60_mean  0.031656\n",
      "11    lang_mean_60_mean  0.033989\n",
      "12       median_overall  0.035322\n",
      "13               max_60  0.042986\n",
      "14             date_num  0.046318\n",
      "15               std_60  0.048984\n",
      "16               min_30  0.059647\n",
      "17            median_30  0.066311\n",
      "18               std_30  0.083639\n",
      "19               max_30  0.093302\n",
      "20         mean_overall  0.129623\n",
      "21              mean_30  0.135288\n"
     ]
    }
   ],
   "source": [
    "importance = bst.get_fscore()\n",
    "\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df_imp = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df_imp['fscore'] = df_imp['fscore']/df_imp['fscore'].sum()\n",
    "\n",
    "print df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# x_train, x_valid, label_train, label_valid = train_test_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "# # x_train = x_train.fillna(0)\n",
    "# # x_valid = x_valid.fillna(0)\n",
    "# reg.fit(x_train, label_train)\n",
    "\n",
    "reg.fit(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction = reg.predict(x_valid)\n",
    "prediction = reg.predict(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.106730814\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(label_valid)\n",
    "y_pred = np.array(prediction)\n",
    "\n",
    "denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "diff = np.abs(y_true - y_pred) / denominator\n",
    "diff[denominator == 0] = 0.0\n",
    "\n",
    "print np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(test_df):\n",
    "    \n",
    "    d_test = xgb.DMatrix(test_df)\n",
    "    p_test = bst.predict(d_test)\n",
    "    \n",
    "    return pd.Series(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overall_df():\n",
    "    \n",
    "    key_wide = pd.DataFrame()\n",
    "    key_wide[\"page\"] = np.unique(key.trunc_page).tolist()\n",
    "    for i in np.unique(key.date).tolist():\n",
    "        key_wide[i] = 0\n",
    "\n",
    "    overall_df = pd.merge(train, key_wide, left_on=\"Page\", right_on = \"page\", how = \"inner\")\n",
    "    overall_df.drop(\"page\", axis = 1, inplace = True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_df(overall_df):\n",
    "    \n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    pred_index = overall_df.columns.tolist().index('2017-01-01')\n",
    "    \n",
    "    for i in range(pred_index, len(overall_df.columns)):\n",
    "\n",
    "        last_date = overall_df.columns.tolist()[i]\n",
    "        print last_date\n",
    "        last_index = i\n",
    "\n",
    "        test_feats = pd.DataFrame()\n",
    "        \n",
    "        test_feats[\"Page\"] = overall_df.Page\n",
    "        test_feats[\"date\"] = last_date\n",
    "        \n",
    "#         test_feats[\"mean_7\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 7, pred_index = pred_index)\n",
    "        test_feats[\"mean_30\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 30, pred_index = pred_index)\n",
    "        test_feats[\"mean_60\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 60, pred_index = pred_index)\n",
    "\n",
    "#         test_feats[\"median_7\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 7, pred_index = pred_index)\n",
    "        test_feats[\"median_30\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 30, pred_index = pred_index)\n",
    "        test_feats[\"median_60\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 60, pred_index = pred_index)\n",
    "\n",
    "#         test_feats[\"mean_diff_7\"] = overall_df.apply(get_mean_diff_test, axis = 1, last_index = last_index)\n",
    "#         test_feats[\"last_day_visits_None\"] = overall_df.apply(get_last_day_visits_test, axis = 1, last_index = last_index)\n",
    "\n",
    "#         test_feats[\"month\"] = last_date.split(\"-\")[1]\n",
    "        test_feats[\"date_num\"] = pd.to_numeric(last_date.split(\"-\")[2])\n",
    "        test_feats[\"weekday\"] = datetime.datetime.strptime(last_date, '%Y-%m-%d').date().weekday()\n",
    "                                \n",
    "        test_df = pd.concat([test_df, test_feats])\n",
    "        \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = get_overall_df()\n",
    "test_df = get_test_df(overall_df)\n",
    "test_df = get_lang_features_test(test_df)\n",
    "test_df.to_csv(\"test_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = get_preds(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]])\n",
    "\n",
    "# prediction = invboxcox(get_preds(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\"]]), ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_index = overall_df.columns.tolist().index(\"2017-01-01\")\n",
    "\n",
    "# pred_df = overall_df.iloc[:, pred_index:]\n",
    "# pred_df[\"Page\"] = overall_df.Page\n",
    "\n",
    "# pred_df_melt = pd.melt(pred_df, id_vars=['Page'], var_name=\"date\", value_name=\"Visits\")        \n",
    "\n",
    "test_df[\"Visits\"] = prediction\n",
    "# pred_df = pd.concat([test_df[[\"Page\", \"date\"]], prediction], axis = 1)\n",
    "pred_df = test_df[[\"Page\", \"date\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits = pd.merge(pred_df, key, left_on=[\"Page\", \"date\"], right_on=[\"trunc_page\", \"date\"], how=\"inner\")[[\"Id\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits.to_csv(\"pred_glm_3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/stats/morestats.py:516: RuntimeWarning: divide by zero encountered in log\n",
      "  y = where(lmbda == 0, log(x), (x**lmbda - 1)/lmbda)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import *\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt if i > 4 and i < 1871])) #Outlier 10% to 90% only\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt]))\n",
    "\n",
    "bc_label = boxcox(np.array(label_train_melt), lmbda=0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invboxcox(y,ld):\n",
    "    if ld == 0:\n",
    "        return(np.exp(y))\n",
    "    else:\n",
    "        return(np.exp(np.log(ld*y+1)/ld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.,  11.,   3., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.percentile(label_train_melt, 90)\n",
    "# np.percentile(label_train_melt, 10)\n",
    "# len([i for i in label_train_melt if i > 4 and i < 1871])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(bc_label.tolist())\n",
    "# plt.show()\n",
    "\n",
    "# bc_label\n",
    "\n",
    "# import scipy.special.inv_boxcox\n",
    "invboxcox(bc_label, ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_mean_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>2</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154368</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154369</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154370</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154371</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154372</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154373</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154374</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154375</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154376</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>3</td>\n",
       "      <td>16.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308736</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308737</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308738</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308739</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308740</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308741</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308742</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308743</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308744</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>4</td>\n",
       "      <td>45.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463104</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463105</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463106</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463107</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463108</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463109</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463110</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463111</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463112</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>5</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617472</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617473</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617474</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617475</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617476</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617477</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617478</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617479</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>6</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754688</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754689</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754690</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754691</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754692</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754693</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754694</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754695</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>0</td>\n",
       "      <td>29.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891904</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891905</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891906</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891907</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891908</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891909</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891910</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891911</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1</td>\n",
       "      <td>24.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Page  weekday  weekday_mean_visits\n",
       "0       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "1       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "2       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "3       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "4       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "5       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "6       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "7       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "8       2NE1_zh.wikipedia.org_all-access_spider        2            19.222222\n",
       "154368  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154369  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154370  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154371  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154372  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154373  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154374  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154375  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "154376  2NE1_zh.wikipedia.org_all-access_spider        3            16.888889\n",
       "308736  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308737  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308738  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308739  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308740  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308741  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308742  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308743  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "308744  2NE1_zh.wikipedia.org_all-access_spider        4            45.555556\n",
       "463104  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463105  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463106  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463107  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463108  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463109  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463110  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463111  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "463112  2NE1_zh.wikipedia.org_all-access_spider        5            16.444444\n",
       "617472  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "617473  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "617474  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "617475  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "617476  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "617477  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "617478  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "617479  2NE1_zh.wikipedia.org_all-access_spider        6            28.000000\n",
       "754688  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "754689  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "754690  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "754691  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "754692  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "754693  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "754694  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "754695  2NE1_zh.wikipedia.org_all-access_spider        0            29.625000\n",
       "891904  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000\n",
       "891905  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000\n",
       "891906  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000\n",
       "891907  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000\n",
       "891908  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000\n",
       "891909  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000\n",
       "891910  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000\n",
       "891911  2NE1_zh.wikipedia.org_all-access_spider        1            24.875000"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_melt[train_melt.Page == \"2NE1_zh.wikipedia.org_all-access_spider\"][[\"Page\", \"weekday\", \"weekday_mean_visits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

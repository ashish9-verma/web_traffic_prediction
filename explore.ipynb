{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# import xgboost as xgb\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('./key_trunc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./sample_submission_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt = pd.read_csv(\"train_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dea6371ed687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train[col] = pd.to_numeric(train[col],downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median(row, last_n_days):\n",
    "    return pd.rolling_median(pd.Series(row), window = last_n_days)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(row, last_n_days):\n",
    "    return pd.rolling_mean(pd.Series(row), window = last_n_days)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_long_stats(func_type, last_n_days, df, df_melt):\n",
    "\n",
    "    if func_type == \"median\":\n",
    "        rolling_stats = df.iloc[:, -60:].progress_apply(get_median, last_n_days = last_n_days, axis = 1)\n",
    "    elif func_type == \"mean\":\n",
    "        rolling_stats = df.iloc[:, -60:].progress_apply(get_mean, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    rolling_stats_df = pd.concat([df.Page, rolling_stats.apply(pd.Series)], axis = 1)    \n",
    "    rolling_stats_df.columns = [\"Page\"] + list(df.columns[-60:])\n",
    "    \n",
    "    rolling_stats_melt = pd.melt(rolling_stats_df, id_vars=['Page'], var_name=\"date\", value_name=func_type + \"_\" + str(last_n_days))\n",
    "    \n",
    "    df_melt = pd.merge(df_melt, rolling_stats_melt, on = [\"Page\", \"date\"])     \n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_melt():\n",
    "\n",
    "    train_melt = pd.melt(pd.concat([train.Page, train.iloc[:, -60:]], axis = 1), id_vars=['Page'], var_name=\"date\", value_name=\"visits\")\n",
    "\n",
    "    train_melt = get_long_stats(\"mean\", 7, train, train_melt)\n",
    "    train_melt = get_long_stats(\"mean\", 30, train, train_melt)\n",
    "    train_melt = get_long_stats(\"mean\", 60, train, train_melt)\n",
    "\n",
    "    train_melt = get_long_stats(\"median\", 7, train, train_melt)\n",
    "    train_melt = get_long_stats(\"median\", 30, train, train_melt)\n",
    "    train_melt = get_long_stats(\"median\", 60, train, train_melt)\n",
    "\n",
    "    train_melt[\"month\"] = train_melt.progress_apply(get_month, axis = 1)\n",
    "    train_melt[\"date_num\"] = train_melt.progress_apply(get_date, axis = 1)\n",
    "    train_melt[\"weekday\"] = train_melt.progress_apply(get_weekday, axis = 1)\n",
    "    # train_melt[\"language\"] = train_melt.progress_apply(get_language, axis = 1)\n",
    "    \n",
    "# generate_train_melt()\n",
    "# train_melt.to_csv(\"train_melt.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_source(row):\n",
    "    return row.Page.split[\".\"][-1].split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language(row):\n",
    "    try:\n",
    "        return row.Page.split(\".\")[0].split(\"_\")[-1]    \n",
    "    except:\n",
    "        return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month(row):\n",
    "    return row.date.split(\"-\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(row):\n",
    "    return row.date.split(\"-\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weekday(row):\n",
    "    return datetime.datetime.strptime(row.date, '%Y-%m-%d').date().weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "en                                                                                                     1393140\n",
      "ja                                                                                                     1220940\n",
      "de                                                                                                     1074780\n",
      "fr                                                                                                     1058940\n",
      "zh                                                                                                     1029120\n",
      "ru                                                                                                      893220\n",
      "es                                                                                                      838140\n",
      "www                                                                                                     413280\n",
      "commons                                                                                                 293280\n",
      "1                                                                                                         9720\n",
      "vs                                                                                                        8700\n",
      "map                                                                                                       8100\n",
      "logo                                                                                                      7380\n",
      "2                                                                                                         6000\n",
      "Jr                                                                                                        5640\n",
      "F                                                                                                         5220\n",
      "J                                                                                                         4320\n",
      "(U                                                                                                        4260\n",
      "01                                                                                                        4260\n",
      "D                                                                                                         4080\n",
      "Logo                                                                                                      3780\n",
      "B                                                                                                         3360\n",
      "2016                                                                                                      3300\n",
      "3                                                                                                         3180\n",
      "M                                                                                                         3060\n",
      "A                                                                                                         2940\n",
      "S                                                                                                         2880\n",
      "Mr                                                                                                        2820\n",
      "(cropped)                                                                                                 2700\n",
      "Dr                                                                                                        2520\n",
      "                                                                                                        ...   \n",
      "areas                                                                                                       60\n",
      "File:MediaWiki-extensions-icon                                                                              60\n",
      "File:Me163                                                                                                  60\n",
      "File:Massarosaw                                                                                             60\n",
      "ani                                                                                                         60\n",
      "w                                                                                                           60\n",
      "anniversary                                                                                                 60\n",
      "antijuive                                                                                                   60\n",
      "File:Logo-bw-vertical1                                                                                      60\n",
      "File:LittleMix15                                                                                            60\n",
      "File:Lipopolysaccharide-O-Antigen-Prevents-Phagocytosis-of-Vibrio-anguillarum-by-Rainbow-Trout-pone         60\n",
      "File:Light-Bulb-Filament-engineerguy                                                                        60\n",
      "File:LayneSomsen                                                                                            60\n",
      "File:LandsteinerWS                                                                                          60\n",
      "article                                                                                                     60\n",
      "File:Howlsnow                                                                                               60\n",
      "File:Jonbonjovi                                                                                             60\n",
      "b                                                                                                           60\n",
      "File:Jamiedodger                                                                                            60\n",
      "background                                                                                                  60\n",
      "File:Izumo-taisha14bs4592                                                                                   60\n",
      "File:Israeli-type-H-plugs-and-socket                                                                        60\n",
      "ballance1                                                                                                   60\n",
      "banner2                                                                                                     60\n",
      "banting                                                                                                     60\n",
      "File:Imaghcacene                                                                                            60\n",
      "beach                                                                                                       60\n",
      "File:IWMLondonThumbnail                                                                                     60\n",
      "File:Hyewon-Jusa                                                                                            60\n",
      "up                                                                                                          60\n",
      "Name: Page, Length: 2121, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# def get_language_mean(row):\n",
    "# lang_count = pd.Series(train_melt.groupby([\"language\"])[\"Page\"].count()).sort_values(axis = 0, ascending = False)\n",
    "# print lang_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_7(row, last_index):\n",
    "    \n",
    "    return np.median(row.iloc[last_index - 7 : last_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_30(row, last_index):\n",
    "    \n",
    "    return np.median(row.iloc[last_index - 30 : last_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_60(row, last_index):\n",
    "    \n",
    "    return np.median(row.iloc[last_index - 60 : last_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_7(row, last_index):\n",
    "    \n",
    "    return np.mean(row.iloc[last_index - 7 : last_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_30(row, last_index):\n",
    "    \n",
    "    return np.mean(row.iloc[last_index - 30 : last_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_60(row, last_index):\n",
    "    \n",
    "    return np.mean(row.iloc[last_index - 60 : last_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_feats(row, last_index):\n",
    "    \n",
    "#     subset_row = row.iloc[last_index - 60 : last_index].tolist()\n",
    "    \n",
    "#     median_7 = np.median(subset_row[-7:])\n",
    "#     median_30 = np.median(subset_row[-30:])\n",
    "#     median_60 = np.median(subset_row[-60:])\n",
    "\n",
    "#     mean_7 = np.mean(subset_row[-7:])\n",
    "#     mean_30 = np.mean(subset_row[-30:])\n",
    "#     mean_60 = np.mean(subset_row[-60:])\n",
    "    \n",
    "#     return pd.Series([row.Page, median_7, median_30, median_60, mean_7, mean_30, mean_60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(test_feats):\n",
    "    \n",
    "    return pd.Series([1 for i in range(0, len(test_feats))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overall_df():\n",
    "    \n",
    "#     key = pd.read_csv(\"key_trunc.csv\")\n",
    "    key_wide = pd.DataFrame()\n",
    "    key_wide[\"page\"] = np.unique(key.trunc_page).tolist()\n",
    "    for i in np.unique(key.date).tolist():\n",
    "        key_wide[i] = 0\n",
    "\n",
    "    overall_df = pd.merge(train, key_wide, left_on=\"Page\", right_on = \"page\", how = \"inner\")\n",
    "    overall_df.drop(\"page\", axis = 1, inplace = True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_and_pred(overall_df):\n",
    "\n",
    "    for i in range(overall_df.columns.tolist().index('2017-01-01'), len(overall_df.columns)):\n",
    "\n",
    "        last_date = overall_df.columns.tolist()[i]\n",
    "        print last_date\n",
    "\n",
    "        last_index = overall_df.columns.tolist().index(last_date)\n",
    "\n",
    "        test_feats = overall_df.Page\n",
    "        test_feats[\"median_7\"] = overall_df.apply(get_median_7, axis = 1, last_index = last_index)\n",
    "        test_feats[\"median_30\"] = overall_df.apply(get_median_30, axis = 1, last_index = last_index)\n",
    "        test_feats[\"median_60\"] = overall_df.apply(get_median_60, axis = 1, last_index = last_index)\n",
    "        test_feats[\"mean_7\"] = overall_df.apply(get_mean_7, axis = 1, last_index = last_index)\n",
    "        test_feats[\"mean_30\"] = overall_df.apply(get_mean_30, axis = 1, last_index = last_index)\n",
    "        test_feats[\"mean_60\"] = overall_df.apply(get_mean_60, axis = 1, last_index = last_index)\n",
    "\n",
    "        test_feats[\"month\"] = last_date.split(\"-\")[1]\n",
    "        test_feats[\"datenum\"] = last_date.split(\"-\")[2]\n",
    "        test_feats[\"weekday\"] = datetime.datetime.strptime(last_date, '%Y-%m-%d').date().weekday()\n",
    "\n",
    "        prediction = get_preds(test_feats)\n",
    "\n",
    "        overall_df[last_date] = prediction\n",
    "        #preds = pd.concat([preds, prediction])\n",
    "        \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "5         1\n",
       "6         1\n",
       "7         1\n",
       "8         1\n",
       "9         1\n",
       "10        1\n",
       "11        1\n",
       "12        1\n",
       "13        1\n",
       "14        1\n",
       "15        1\n",
       "16        1\n",
       "17        1\n",
       "18        1\n",
       "19        1\n",
       "20        1\n",
       "21        1\n",
       "22        1\n",
       "23        1\n",
       "24        1\n",
       "25        1\n",
       "26        1\n",
       "27        1\n",
       "28        1\n",
       "29        1\n",
       "         ..\n",
       "145033    1\n",
       "145034    1\n",
       "145035    1\n",
       "145036    1\n",
       "145037    1\n",
       "145038    1\n",
       "145039    1\n",
       "145040    1\n",
       "145041    1\n",
       "145042    1\n",
       "145043    1\n",
       "145044    1\n",
       "145045    1\n",
       "145046    1\n",
       "145047    1\n",
       "145048    1\n",
       "145049    1\n",
       "145050    1\n",
       "145051    1\n",
       "145052    1\n",
       "145053    1\n",
       "145054    1\n",
       "145055    1\n",
       "145056    1\n",
       "145057    1\n",
       "145058    1\n",
       "145059    1\n",
       "145060    1\n",
       "145061    1\n",
       "145062    1\n",
       "Name: 2017-01-01, Length: 145063, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df = get_overall_df()\n",
    "overall_df = test_and_pred(overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_melt = pd.read_csv(\"train_feats.csv\")\n",
    "key = pd.read_csv(\"key_trunc.csv\")\n",
    "\n",
    "train_melt = pd.merge(train_melt, key, left_on=\"Page\", right_on=\"trunc_page\", how=\"inner\")\n",
    "train_melt.drop(\"Page_x\", inplace=True, axis = 1)\n",
    "train_melt.drop(\"Page_y\", inplace=True, axis = 1)\n",
    "\n",
    "train_melt.to_csv(\"train_merged.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged_filtered = train_merged[[\"Id\", \"median_60_days\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.merge(sub, train_merged_filtered, on = \"Id\")\n",
    "sub.drop(\"Visits\", inplace=True, axis = 1)\n",
    "sub.columns = [\"Id\", \"Visits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"median_60_days.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(x_train, x_test, x_label):\n",
    "\n",
    "    # x_train = pd.concat([pos_train, neg_train]) #Concat positive and negative\n",
    "    # y_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist() #Putting in 1 and 0\n",
    "\n",
    "    # x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    params['eta'] = 0.05\n",
    "    params['max_depth'] = 6\n",
    "    params['silent'] = 1\n",
    "\n",
    "    d_train = xgb.DMatrix(x_train, label=x_label)\n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "\n",
    "    watchlist = [(d_train, 'train')]\n",
    "\n",
    "    bst = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "\n",
    "    p_test = bst.predict(d_test)\n",
    "\n",
    "    # xgb.plot_importance(bst)\n",
    "    # pyplot.show()\n",
    "\n",
    "    return p_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "import datetime\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import operator\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('./key_trunc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./sample_submission_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt = pd.read_csv(\"train_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-dea6371ed687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3745\u001b[0;31m                     \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3746\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   3284\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3286\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train[col] = pd.to_numeric(train[col],downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median(row, last_n_days, rows_to_consider, is_it_train):\n",
    "    if is_it_train == 1:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).median()[rows_to_consider:])\n",
    "    else:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).median()[rows_to_consider - 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(row, last_n_days, rows_to_consider, is_it_train):\n",
    "    if is_it_train == 1:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).mean()[rows_to_consider:]) \n",
    "    else:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).mean()[rows_to_consider - 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_std(row, last_n_days, rows_to_consider, is_it_train):\n",
    "    if is_it_train == 1:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).std()[rows_to_consider:])\n",
    "    else:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).std()[rows_to_consider - 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_min(row, last_n_days, rows_to_consider, is_it_train):\n",
    "    if is_it_train == 1:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).min()[rows_to_consider:])\n",
    "    else:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).min()[rows_to_consider - 1:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max(row, last_n_days, rows_to_consider, is_it_train):\n",
    "    if is_it_train == 1:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).max()[rows_to_consider:])\n",
    "    else:\n",
    "        return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).max()[rows_to_consider - 1:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_overall(row, rows_to_consider, is_it_train):\n",
    "    if is_it_train == 1:\n",
    "        return pd.Series(pd.Series(row)[1:].mean()).repeat(-1*rows_to_consider)\n",
    "    else:\n",
    "        return pd.Series(pd.Series(row)[1:].mean()).repeat(len(row) - rows_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_overall(row, rows_to_consider, is_it_train):\n",
    "    if is_it_train == 1:\n",
    "        return pd.Series(pd.Series(row)[1:].median()).repeat(-1*rows_to_consider)\n",
    "    else:\n",
    "        return pd.Series(pd.Series(row)[1:].median()).repeat(len(row) - rows_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mean_diff(row, last_n_days):\n",
    "#     return pd.Series(pd.rolling_mean(np.diff(pd.Series(row)), window = last_n_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_last_day_visits(row):\n",
    "#     return row[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_long_stats(func_type, df, df_melt, rows_to_consider, is_it_train = None, last_n_days = None):\n",
    "\n",
    "    if func_type == \"median\":\n",
    "        rolling_stats = df.apply(get_median, last_n_days = last_n_days, rows_to_consider = rows_to_consider,is_it_train = is_it_train, axis = 1)\n",
    "        \n",
    "    elif func_type == \"mean\":\n",
    "        rolling_stats = df.apply(get_mean, last_n_days = last_n_days, rows_to_consider = rows_to_consider, is_it_train = is_it_train, axis = 1)\n",
    "    \n",
    "    elif func_type == \"std\":\n",
    "        rolling_stats = df.apply(get_std, last_n_days = last_n_days, rows_to_consider = rows_to_consider, is_it_train = is_it_train, axis = 1)\n",
    "\n",
    "    elif func_type == \"min\":\n",
    "        rolling_stats = df.apply(get_min, last_n_days = last_n_days, rows_to_consider = rows_to_consider, is_it_train = is_it_train, axis = 1)\n",
    "\n",
    "    elif func_type == \"max\":\n",
    "        rolling_stats = df.apply(get_max, last_n_days = last_n_days, rows_to_consider = rows_to_consider, is_it_train = is_it_train, axis = 1)\n",
    "\n",
    "    elif func_type == \"mean_overall\":\n",
    "        rolling_stats = df.apply(get_mean_overall, rows_to_consider = rows_to_consider, is_it_train = is_it_train, axis = 1)\n",
    "\n",
    "    elif func_type == \"median_overall\":\n",
    "        rolling_stats = df.apply(get_median_overall, rows_to_consider = rows_to_consider, is_it_train = is_it_train, axis = 1)\n",
    "        \n",
    "    rolling_stats_df = pd.concat([df.Page, rolling_stats.apply(pd.Series)], axis = 1)  \n",
    "    rolling_stats_df.columns = [\"Page\"] + list(df.columns[rows_to_consider:])\n",
    "    \n",
    "    rolling_stats_df = pd.melt(rolling_stats_df, id_vars=['Page'], var_name=\"date\", value_name=func_type + \"_\" + str(last_n_days))        \n",
    "    \n",
    "    df_melt = pd.merge(df_melt, rolling_stats_df, on = [\"Page\", \"date\"])     \n",
    "    \n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Page        date  visits  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
      "\n",
      "     mean_30    mean_60  \n",
      "0  19.000000  21.066667  \n",
      "1  39.933333  35.983333  \n",
      "2   4.066667   4.983333  \n",
      "3  19.066667  19.233333  \n",
      "4  13.833333  10.350000  \n",
      "                                                Page        date  visits  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
      "\n",
      "     mean_30    mean_60  median_30  median_60  \n",
      "0  19.000000  21.066667       16.0       17.5  \n",
      "1  39.933333  35.983333       26.0       25.5  \n",
      "2   4.066667   4.983333        4.0        4.0  \n",
      "3  19.066667  19.233333       14.0       14.5  \n",
      "4  13.833333  10.350000        7.0        6.0  \n",
      "                                                Page        date  visits  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
      "\n",
      "     mean_30    mean_60  median_30  median_60     std_30     std_60  \n",
      "0  19.000000  21.066667       16.0       17.5  10.218307  13.528209  \n",
      "1  39.933333  35.983333       26.0       25.5  38.361199  30.086030  \n",
      "2   4.066667   4.983333        4.0        4.0   2.242741   3.270265  \n",
      "3  19.066667  19.233333       14.0       14.5  18.339581  17.188256  \n",
      "4  13.833333  10.350000        7.0        6.0  30.440539  22.998029  \n",
      "                                                Page        date  visits  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
      "\n",
      "     mean_30    mean_60  median_30  median_60     std_30     std_60  min_30  \\\n",
      "0  19.000000  21.066667       16.0       17.5  10.218307  13.528209     8.0   \n",
      "1  39.933333  35.983333       26.0       25.5  38.361199  30.086030    11.0   \n",
      "2   4.066667   4.983333        4.0        4.0   2.242741   3.270265     0.0   \n",
      "3  19.066667  19.233333       14.0       14.5  18.339581  17.188256     4.0   \n",
      "4  13.833333  10.350000        7.0        6.0  30.440539  22.998029     2.0   \n",
      "\n",
      "   min_60  \n",
      "0     8.0  \n",
      "1    11.0  \n",
      "2     0.0  \n",
      "3     4.0  \n",
      "4     0.0  \n",
      "                                                Page        date  visits  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
      "\n",
      "     mean_30    mean_60  median_30  median_60     std_30     std_60  min_30  \\\n",
      "0  19.000000  21.066667       16.0       17.5  10.218307  13.528209     8.0   \n",
      "1  39.933333  35.983333       26.0       25.5  38.361199  30.086030    11.0   \n",
      "2   4.066667   4.983333        4.0        4.0   2.242741   3.270265     0.0   \n",
      "3  19.066667  19.233333       14.0       14.5  18.339581  17.188256     4.0   \n",
      "4  13.833333  10.350000        7.0        6.0  30.440539  22.998029     2.0   \n",
      "\n",
      "   min_60  max_30  max_60  \n",
      "0     8.0    50.0    72.0  \n",
      "1    11.0   179.0   179.0  \n",
      "2     0.0    11.0    19.0  \n",
      "3     4.0   103.0   103.0  \n",
      "4     0.0   173.0   173.0  \n",
      "                                                Page        date  visits  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
      "\n",
      "     mean_30    mean_60  median_30  median_60     std_30     std_60  min_30  \\\n",
      "0  19.000000  21.066667       16.0       17.5  10.218307  13.528209     8.0   \n",
      "1  39.933333  35.983333       26.0       25.5  38.361199  30.086030    11.0   \n",
      "2   4.066667   4.983333        4.0        4.0   2.242741   3.270265     0.0   \n",
      "3  19.066667  19.233333       14.0       14.5  18.339581  17.188256     4.0   \n",
      "4  13.833333  10.350000        7.0        6.0  30.440539  22.998029     2.0   \n",
      "\n",
      "   min_60  max_30  max_60  mean_overall_60  median_overall_60  \n",
      "0     8.0    50.0    72.0        21.756364               16.0  \n",
      "1    11.0   179.0   179.0        25.392727               17.0  \n",
      "2     0.0    11.0    19.0         5.203636                4.0  \n",
      "3     4.0   103.0   103.0        17.125455               13.0  \n",
      "4     0.0   173.0   173.0         4.840000                0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/145063 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Page        date  visits  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider  2016-11-02    18.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider  2016-11-02    11.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider  2016-11-02     3.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider  2016-11-02    12.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...  2016-11-02     5.0   \n",
      "\n",
      "     mean_30    mean_60  median_30  median_60     std_30     std_60  min_30  \\\n",
      "0  19.000000  21.066667       16.0       17.5  10.218307  13.528209     8.0   \n",
      "1  39.933333  35.983333       26.0       25.5  38.361199  30.086030    11.0   \n",
      "2   4.066667   4.983333        4.0        4.0   2.242741   3.270265     0.0   \n",
      "3  19.066667  19.233333       14.0       14.5  18.339581  17.188256     4.0   \n",
      "4  13.833333  10.350000        7.0        6.0  30.440539  22.998029     2.0   \n",
      "\n",
      "   min_60  max_30  max_60  mean_overall_60  median_overall_60 date_num  \\\n",
      "0     8.0    50.0    72.0        21.756364               16.0       02   \n",
      "1    11.0   179.0   179.0        25.392727               17.0       02   \n",
      "2     0.0    11.0    19.0         5.203636                4.0       02   \n",
      "3     4.0   103.0   103.0        17.125455               13.0       02   \n",
      "4     0.0   173.0   173.0         4.840000                0.0       02   \n",
      "\n",
      "   weekday  \n",
      "0        2  \n",
      "1        2  \n",
      "2        2  \n",
      "3        2  \n",
      "4        2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145063/145063 [00:14<00:00, 9777.78it/s] \n"
     ]
    }
   ],
   "source": [
    "def generate_train_melt(train):\n",
    "    \n",
    "    train_melt = pd.melt(pd.concat([train.Page, \n",
    "                                    train.iloc[:, -60:]],\n",
    "                                    axis = 1),\n",
    "                                    id_vars=['Page'], \n",
    "                                    var_name=\"date\", value_name=\"visits\")\n",
    "\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=30)\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=60)\n",
    "    print train_melt.head()\n",
    "    \n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=30)\n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=30)\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=30)\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=30)\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=60)\n",
    "    print train_melt.head()\n",
    "\n",
    "    train_melt = get_long_stats(\"mean_overall\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=60)\n",
    "    train_melt = get_long_stats(\"median_overall\", train, train_melt, rows_to_consider=-60, is_it_train = 1, last_n_days=60)\n",
    "    print train_melt.head()\n",
    "        \n",
    "    train_melt[\"date_num\"] = train_melt.apply(get_date, axis = 1)\n",
    "    train_melt[\"weekday\"] = train_melt.apply(get_weekday, axis = 1)\n",
    "    print train_melt.head()\n",
    "    \n",
    "    return train_melt \n",
    "\n",
    "def get_lang_features(train_melt):\n",
    "    \n",
    "    train_melt = pd.merge(train_melt, pd.concat([train.Page, train.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    train_melt.columns = ['Page', 'date', 'visits', 'mean_30', 'mean_60', 'median_30', 'median_60', 'std_30', 'std_60', 'min_30', 'min_60', 'max_30', 'max_60', 'mean_overall', 'median_overall', 'date_num', 'weekday', 'language']\n",
    "    \n",
    "    lang_date_melt = train_melt[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\", \"min_30\", \"min_60\", \"max_30\", \"max_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "\n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\", \"lang_min_30_mean\", \"lang_min_60_mean\", \"lang_max_30_mean\", \"lang_max_60_mean\"]\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return train_melt\n",
    "\n",
    "def get_weekday_features(train_melt):\n",
    "    \n",
    "    weekday_page_melt = train_melt[[\"weekday\", \"Page\", \"visits\"]]\n",
    "    \n",
    "    weekday_mean_feats = pd.DataFrame(weekday_page_melt.groupby([\"weekday\", \"Page\"], as_index = False).aggregate(np.mean))\n",
    "    weekday_mean_feats.columns = [\"weekday\", \"Page\", \"weekday_mean_visits\"]\n",
    "    \n",
    "    weekday_median_feats = pd.DataFrame(weekday_page_melt.groupby([\"weekday\", \"Page\"], as_index = False).aggregate(np.median))\n",
    "    weekday_median_feats.columns = [\"weekday\", \"Page\", \"weekday_median_visits\"]\n",
    "    \n",
    "    weekday_feats = pd.merge(weekday_mean_feats, weekday_median_feats, on = [\"weekday\", \"Page\"])\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, weekday_feats, on = [\"weekday\", \"Page\"])\n",
    "    \n",
    "    return train_melt\n",
    "    \n",
    "# def get_lang_mean(train_melt):\n",
    "    \n",
    "#     language_page_melt = train_melt[[\"language\", \"date\", \"visits\"]]\n",
    "    \n",
    "#     language_feats = pd.DataFrame(language_page_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "\n",
    "#     language_feats.columns = [\"language\", \"date\", \"lang_mean_visits\"]\n",
    "        \n",
    "#     train_melt = pd.merge(train_melt, language_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "#     return train_melt\n",
    "\n",
    "train_melt = generate_train_melt(train)\n",
    "train_melt = get_lang_features(train_melt)\n",
    "train_melt = get_weekday_features(train_melt)\n",
    "train_melt.to_csv(\"train_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_source(row):\n",
    "    return row.Page.split[\".\"][-1].split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language(row):\n",
    "    try:\n",
    "        return row.Page.split(\".\")[0].split(\"_\")[-1]    \n",
    "    except:\n",
    "        return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month(row):\n",
    "    return row.date.split(\"-\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(row):\n",
    "    return row.date.split(\"-\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weekday(row):\n",
    "    return datetime.datetime.strptime(row.date, '%Y-%m-%d').date().weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_language_mean(row):\n",
    "# lang_count = pd.Series(train_melt.groupby([\"language\"])[\"Page\"].count()).sort_values(axis = 0, ascending = False)\n",
    "# print lang_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lang_features_test(test_melt):\n",
    "    \n",
    "    test_melt = pd.merge(test_melt, pd.concat([overall_df.Page, overall_df.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    test_melt.columns = ['Page', 'date', 'visits', 'mean_30', 'mean_60', 'median_30', 'median_60', 'std_30', 'std_60', 'min_30', 'min_60', 'max_30', 'max_60', 'mean_overall', 'median_overall', 'date_num', 'weekday', 'language']\n",
    "    \n",
    "    lang_date_melt = test_melt[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\", \"min_30\", \"min_60\", \"max_30\", \"max_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "    \n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\", \"lang_min_30_mean\", \"lang_min_60_mean\", \"lang_max_30_mean\", \"lang_max_60_mean\"]\n",
    "        \n",
    "    test_melt = pd.merge(test_melt, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return test_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weekday_features_test(train_melt, test_melt):\n",
    "    \n",
    "    weekday_page_melt = train_melt[[\"weekday\", \"Page\", \"visits\"]]\n",
    "    \n",
    "    weekday_mean_feats = pd.DataFrame(weekday_page_melt.groupby([\"weekday\", \"Page\"], as_index = False).aggregate(np.mean))\n",
    "    weekday_mean_feats.columns = [\"weekday\", \"Page\", \"weekday_mean_visits\"]\n",
    "    \n",
    "    weekday_median_feats = pd.DataFrame(weekday_page_melt.groupby([\"weekday\", \"Page\"], as_index = False).aggregate(np.median))\n",
    "    weekday_median_feats.columns = [\"weekday\", \"Page\", \"weekday_median_visits\"]\n",
    "    \n",
    "    weekday_feats = pd.merge(weekday_mean_feats, weekday_median_feats, on = [\"weekday\", \"Page\"])\n",
    "        \n",
    "    test_melt = pd.merge(test_melt, weekday_feats, on = [\"weekday\", \"Page\"], how=\"left\")\n",
    "    \n",
    "    return test_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_last_day_visits_test(row, last_index):\n",
    "    \n",
    "#     return row.iloc[last_index - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "        \n",
    "    y_true = y_true.get_label()\n",
    "    y_pred = np.array(y_pred)\n",
    "        \n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "\n",
    "    return \"smape\", np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(train, label_train, valid = None, label_valid = None):\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'reg:linear'\n",
    "    params['eta'] = 0.05\n",
    "    params['max_depth'] = 7\n",
    "    params['silent'] = 1\n",
    "    params['min_child_weight'] = 0\n",
    "    params['subsample'] = 1\n",
    "    params['colsample_bytree'] = 1\n",
    "    params['nthread'] = 13\n",
    "    params['gamma'] = 0\n",
    "    params['max_delta_step'] = 0\n",
    "    \n",
    "    d_train = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    if valid is not None:\n",
    "        d_valid = xgb.DMatrix(valid, label=label_valid)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'validation')]\n",
    "    else:\n",
    "        watchlist = [(d_train, 'train')]\n",
    "        \n",
    "    bst = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=10, verbose_eval=10, feval=smape, maximize = False)\n",
    "\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_train_melt = np.log1p(train_melt[\"visits\"])\n",
    "label_train_melt = train_melt[\"visits\"]\n",
    "\n",
    "# label_train_melt = boxcox(np.array(label_train_melt), lmbda=0.094) #lambda found from default boxcox on outlier-stripped data\n",
    "\n",
    "# label_train_melt = [0] + np.diff(train_melt[\"visits\"]).tolist()\n",
    "\n",
    "train_melt.drop(\"visits\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"date\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"language\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"Page\", axis = 1, inplace = True)\n",
    "\n",
    "# train_melt.date_num = pd.to_numeric(train_melt.date_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt.drop(\"date_num\", axis = 1, inplace=True)\n",
    "train_melt.drop(\"weekday\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:78327.6\ttrain-smape:153.951\n",
      "Multiple eval metrics have been passed: 'train-smape' will be used for early stopping.\n",
      "\n",
      "Will train until train-smape hasn't improved in 10 rounds.\n",
      "[10]\ttrain-rmse:58218.3\ttrain-smape:84.0614\n",
      "[20]\ttrain-rmse:48683.3\ttrain-smape:64.5369\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_valid, label_train, label_valid = train_teąst_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "# bst = run_xgb(x_train, label_train, x_valid, label_valid)\n",
    "\n",
    "bst = run_xgb(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = bst.get_fscore()\n",
    "\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df_imp = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df_imp['fscore'] = df_imp['fscore']/df_imp['fscore'].sum()\n",
    "\n",
    "print df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# x_train, x_valid, label_train, label_valid = train_test_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "# # x_train = x_train.fillna(0)\n",
    "# # x_valid = x_valid.fillna(0)\n",
    "# reg.fit(x_train, label_train)\n",
    "\n",
    "reg.fit(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction = reg.predict(x_valid)\n",
    "prediction = reg.predict(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.106730814\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(label_valid)\n",
    "y_pred = np.array(prediction)\n",
    "\n",
    "denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "diff = np.abs(y_true - y_pred) / denominator\n",
    "diff[denominator == 0] = 0.0\n",
    "\n",
    "print np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(test_df):\n",
    "    \n",
    "    d_test = xgb.DMatrix(test_df)\n",
    "    p_test = bst.predict(d_test)\n",
    "    \n",
    "    return pd.Series(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overall_df():\n",
    "    \n",
    "    key_wide = pd.DataFrame()\n",
    "    key_wide[\"page\"] = np.unique(key.trunc_page).tolist()\n",
    "    for i in np.unique(key.date).tolist():\n",
    "        key_wide[i] = np.nan\n",
    "\n",
    "    overall_df = pd.merge(train, key_wide, left_on=\"Page\", right_on = \"page\", how = \"inner\")\n",
    "    overall_df.drop(\"page\", axis = 1, inplace = True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test_melt(overall_df):\n",
    "        \n",
    "    pred_index = overall_df.columns.tolist().index('2017-01-01') \n",
    "    \n",
    "    test_melt = pd.melt(pd.concat([overall_df.Page, overall_df.iloc[:, pred_index:]],axis = 1),\n",
    "                                id_vars=['Page'], \n",
    "                                var_name=\"date\", value_name=\"visits\")\n",
    "    \n",
    "    test_melt = get_long_stats(\"mean\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 30)\n",
    "    test_melt = get_long_stats(\"mean\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 60)\n",
    "\n",
    "    test_melt = get_long_stats(\"median\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 30)\n",
    "    test_melt = get_long_stats(\"median\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 60)\n",
    "\n",
    "    test_melt = get_long_stats(\"std\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 30)\n",
    "    test_melt = get_long_stats(\"std\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 60)\n",
    "\n",
    "    test_melt = get_long_stats(\"min\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 30)\n",
    "    test_melt = get_long_stats(\"min\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 60)\n",
    "\n",
    "    test_melt = get_long_stats(\"max\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 30)\n",
    "    test_melt = get_long_stats(\"max\", overall_df, test_melt, pred_index, is_it_train=0, last_n_days = 60)\n",
    "\n",
    "    test_melt = get_long_stats(\"mean_overall\", overall_df, test_melt, rows_to_consider = pred_index, is_it_train=0, last_n_days = 60)\n",
    "    test_melt = get_long_stats(\"median_overall\", overall_df, test_melt, rows_to_consider = pred_index, is_it_train=0, last_n_days = 60)\n",
    "    \n",
    "    test_melt[\"date_num\"] = test_melt.apply(get_date, axis = 1)\n",
    "    test_melt[\"weekday\"] = test_melt.apply(get_weekday, axis = 1)\n",
    "\n",
    "    return test_melt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = get_overall_df()\n",
    "\n",
    "test_melt = generate_test_melt(overall_df)\n",
    "test_melt_safety = test_melt\n",
    "\n",
    "test_melt = get_lang_features_test(test_melt)\n",
    "test_melt_safety = test_melt\n",
    "\n",
    "test_melt = get_weekday_features_test(train_melt, test_melt)\n",
    "test_melt_safety = test_melt\n",
    "\n",
    "test_melt.drop(\"visits\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_30\n",
      "mean_60\n",
      "median_30\n",
      "median_60\n",
      "std_30\n",
      "std_60\n",
      "min_30\n",
      "min_60\n",
      "max_30\n",
      "max_60\n",
      "mean_overall\n",
      "median_overall\n",
      "date_num\n",
      "weekday\n",
      "lang_mean_30_mean\n",
      "lang_mean_60_mean\n",
      "lang_median_30_mean\n",
      "lang_median_60_mean\n",
      "lang_min_30_mean\n",
      "lang_min_60_mean\n",
      "lang_max_30_mean\n",
      "lang_max_60_mean\n",
      "weekday_mean_visits\n",
      "weekday_median_visits\n",
      "Visits\n"
     ]
    }
   ],
   "source": [
    "for i in test_melt.columns.tolist():\n",
    "\n",
    "    if i not in [\"Page\", \"date\", \"language\"]:\n",
    "        \n",
    "        test_melt['date'] = pd.to_datetime(test_melt['date'])\n",
    "\n",
    "        sub_test_melt = test_melt[[\"Page\", \"date\", i]]\n",
    "\n",
    "        non_na_sub = sub_test_melt[np.isfinite(sub_test_melt[i])]\n",
    "        last_date = non_na_sub.loc[non_na_sub['date'].idxmax()][\"date\"]\n",
    "\n",
    "        last_rows = non_na_sub[non_na_sub[\"date\"] == last_date][[\"Page\", i]]\n",
    "        sub_test_melt = pd.merge(sub_test_melt, last_rows, on=\"Page\")\n",
    "\n",
    "        sub_test_melt[i + \"_x\"].fillna(sub_test_melt[i + \"_y\"], inplace = True)\n",
    "\n",
    "        test_melt[i] = sub_test_melt[i + \"_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-770-3f806fedfdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_melt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_feats.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1590\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/formats/format.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1691\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/io/formats/format.pyc\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1717\u001b[0m                                         quoting=self.quoting)\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_melt.to_csv(\"test_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_melt = pd.read_csv(\"test_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_melt.date_num = pd.to_numeric(test_melt.date_num)\n",
    "prediction = get_preds(test_melt[train_melt.columns.tolist()])\n",
    "\n",
    "# prediction = invboxcox(get_preds(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\"]]), ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_index = overall_df.columns.tolist().index(\"2017-01-01\")\n",
    "\n",
    "# pred_df = overall_df.iloc[:, pred_index:]\n",
    "# pred_df[\"Page\"] = overall_df.Page\n",
    "\n",
    "# pred_df_melt = pd.melt(pred_df, id_vars=['Page'], var_name=\"date\", value_name=\"Visits\")        \n",
    "\n",
    "test_melt[\"Visits\"] = prediction\n",
    "# pred_df = pd.concat([test_melt[[\"Page\", \"date\"]], prediction], axis = 1)\n",
    "pred_df = test_melt[[\"Page\", \"date\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits = pd.merge(pred_df, key, left_on=[\"Page\", \"date\"], right_on=[\"trunc_page\", \"date\"], how=\"inner\")[[\"Id\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits.to_csv(\"pred_xgb_9.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/stats/morestats.py:516: RuntimeWarning: divide by zero encountered in log\n",
      "  y = where(lmbda == 0, log(x), (x**lmbda - 1)/lmbda)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import *\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt if i > 4 and i < 1871])) #Outlier 10% to 90% only\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt]))\n",
    "\n",
    "bc_label = boxcox(np.array(label_train_melt), lmbda=0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invboxcox(y,ld):\n",
    "    if ld == 0:\n",
    "        return(np.exp(y))\n",
    "    else:\n",
    "        return(np.exp(np.log(ld*y+1)/ld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.,  11.,   3., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.percentile(label_train_melt, 90)\n",
    "# np.percentile(label_train_melt, 10)\n",
    "# len([i for i in label_train_melt if i > 4 and i < 1871])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(bc_label.tolist())\n",
    "# plt.show()\n",
    "\n",
    "# bc_label\n",
    "\n",
    "# import scipy.special.inv_boxcox\n",
    "invboxcox(bc_label, ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_30</th>\n",
       "      <th>mean_60</th>\n",
       "      <th>median_30</th>\n",
       "      <th>median_60</th>\n",
       "      <th>std_30</th>\n",
       "      <th>std_60</th>\n",
       "      <th>min_30</th>\n",
       "      <th>min_60</th>\n",
       "      <th>max_30</th>\n",
       "      <th>max_60</th>\n",
       "      <th>...</th>\n",
       "      <th>lang_mean_30_mean</th>\n",
       "      <th>lang_mean_60_mean</th>\n",
       "      <th>lang_median_30_mean</th>\n",
       "      <th>lang_median_60_mean</th>\n",
       "      <th>lang_min_30_mean</th>\n",
       "      <th>lang_min_60_mean</th>\n",
       "      <th>lang_max_30_mean</th>\n",
       "      <th>lang_max_60_mean</th>\n",
       "      <th>weekday_mean_visits</th>\n",
       "      <th>weekday_median_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>21.066667</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>10.218307</td>\n",
       "      <td>13.528209</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.438147</td>\n",
       "      <td>379.927954</td>\n",
       "      <td>315.525245</td>\n",
       "      <td>304.581885</td>\n",
       "      <td>199.268657</td>\n",
       "      <td>166.883804</td>\n",
       "      <td>1055.840427</td>\n",
       "      <td>1658.632113</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.2</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.956583</td>\n",
       "      <td>14.492780</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>378.933368</td>\n",
       "      <td>381.809727</td>\n",
       "      <td>315.758891</td>\n",
       "      <td>306.031104</td>\n",
       "      <td>201.449335</td>\n",
       "      <td>167.260319</td>\n",
       "      <td>1192.018540</td>\n",
       "      <td>1754.783116</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.2</td>\n",
       "      <td>20.383333</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.866422</td>\n",
       "      <td>13.425364</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>381.535557</td>\n",
       "      <td>379.775191</td>\n",
       "      <td>316.083168</td>\n",
       "      <td>305.969012</td>\n",
       "      <td>200.471024</td>\n",
       "      <td>173.638876</td>\n",
       "      <td>1242.917502</td>\n",
       "      <td>1755.276236</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.3</td>\n",
       "      <td>20.383333</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>13.565041</td>\n",
       "      <td>13.762011</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>381.815050</td>\n",
       "      <td>381.039585</td>\n",
       "      <td>314.788130</td>\n",
       "      <td>306.329087</td>\n",
       "      <td>201.671875</td>\n",
       "      <td>174.939949</td>\n",
       "      <td>1273.689657</td>\n",
       "      <td>1787.523554</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>22.616667</td>\n",
       "      <td>16.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>36.058382</td>\n",
       "      <td>26.627431</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>384.252581</td>\n",
       "      <td>381.005611</td>\n",
       "      <td>316.555533</td>\n",
       "      <td>304.460413</td>\n",
       "      <td>198.830457</td>\n",
       "      <td>175.090368</td>\n",
       "      <td>1327.104303</td>\n",
       "      <td>1829.668843</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_30    mean_60  median_30  median_60     std_30     std_60  min_30  \\\n",
       "0     19.0  21.066667       16.0       17.5  10.218307  13.528209     8.0   \n",
       "1     21.2  21.400000       17.0       16.0  13.956583  14.492780     8.0   \n",
       "2     20.2  20.383333       17.0       16.0  12.866422  13.425364     8.0   \n",
       "3     20.3  20.383333       16.0       15.5  13.565041  13.762011     6.0   \n",
       "4     27.0  22.616667       16.5       15.5  36.058382  26.627431     6.0   \n",
       "\n",
       "   min_60  max_30  max_60          ...            lang_mean_30_mean  \\\n",
       "0     8.0    50.0    72.0          ...                   375.438147   \n",
       "1     8.0    67.0    72.0          ...                   378.933368   \n",
       "2     8.0    67.0    72.0          ...                   381.535557   \n",
       "3     6.0    67.0    72.0          ...                   381.815050   \n",
       "4     6.0   204.0   204.0          ...                   384.252581   \n",
       "\n",
       "   lang_mean_60_mean  lang_median_30_mean  lang_median_60_mean  \\\n",
       "0         379.927954           315.525245           304.581885   \n",
       "1         381.809727           315.758891           306.031104   \n",
       "2         379.775191           316.083168           305.969012   \n",
       "3         381.039585           314.788130           306.329087   \n",
       "4         381.005611           316.555533           304.460413   \n",
       "\n",
       "   lang_min_30_mean  lang_min_60_mean  lang_max_30_mean  lang_max_60_mean  \\\n",
       "0        199.268657        166.883804       1055.840427       1658.632113   \n",
       "1        201.449335        167.260319       1192.018540       1754.783116   \n",
       "2        200.471024        173.638876       1242.917502       1755.276236   \n",
       "3        201.671875        174.939949       1273.689657       1787.523554   \n",
       "4        198.830457        175.090368       1327.104303       1829.668843   \n",
       "\n",
       "   weekday_mean_visits  weekday_median_visits  \n",
       "0            19.222222                   17.0  \n",
       "1            19.222222                   17.0  \n",
       "2            19.222222                   17.0  \n",
       "3            19.222222                   17.0  \n",
       "4            19.222222                   17.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_melt.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

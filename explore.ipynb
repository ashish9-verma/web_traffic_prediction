{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "import datetime\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import operator\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_1.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('./key_trunc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./sample_submission_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_melt = pd.read_csv(\"train_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-dea6371ed687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3745\u001b[0;31m                     \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3746\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   3284\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3286\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train[col] = pd.to_numeric(train[col],downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).median()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).mean()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_std(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).std()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_min(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).min()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max(row, last_n_days):\n",
    "    return pd.Series(pd.Series(row)[1:].rolling(min_periods=7,window=last_n_days,center=False).max()[-60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_overall(row):\n",
    "    return pd.Series(pd.Series(row)[1:].mean()).repeat(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_overall(row):\n",
    "    return pd.Series(pd.Series(row)[1:].median()).repeat(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mean_diff(row, last_n_days):\n",
    "#     return pd.Series(pd.rolling_mean(np.diff(pd.Series(row)), window = last_n_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_last_day_visits(row):\n",
    "#     return row[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_long_stats(func_type, df, df_melt, last_n_days = None):\n",
    "\n",
    "    if func_type == \"median\":\n",
    "        rolling_stats = df.apply(get_median, last_n_days = last_n_days, axis = 1)\n",
    "        \n",
    "    elif func_type == \"mean\":\n",
    "        rolling_stats = df.apply(get_mean, last_n_days = last_n_days, axis = 1)\n",
    "    \n",
    "    elif func_type == \"std\":\n",
    "        rolling_stats = df.apply(get_std, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"min\":\n",
    "        rolling_stats = df.apply(get_min, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"max\":\n",
    "        rolling_stats = df.apply(get_max, last_n_days = last_n_days, axis = 1)\n",
    "\n",
    "    elif func_type == \"mean_overall\":\n",
    "        rolling_stats = df.apply(get_mean_overall, axis = 1)\n",
    "\n",
    "    elif func_type == \"median_overall\":\n",
    "        rolling_stats = df.apply(get_median_overall, axis = 1)\n",
    "\n",
    "#     elif func_type == \"mean_diff\":\n",
    "#         rolling_stats = df.iloc[:, -61:].progress_apply(get_mean_diff, last_n_days = last_n_days, axis = 1)\n",
    "        \n",
    "#     elif func_type == \"last_day_visits\":        \n",
    "#         rolling_stats = df.iloc[:, -61:].progress_apply(get_last_day_visits, axis = 1)\n",
    "    \n",
    "    rolling_stats_df = pd.concat([df.Page, rolling_stats.apply(pd.Series)], axis = 1)  \n",
    "    rolling_stats_df.columns = [\"Page\"] + list(df.columns[-60:])\n",
    "    \n",
    "    rolling_stats_df = pd.melt(rolling_stats_df, id_vars=['Page'], var_name=\"date\", value_name=func_type + \"_\" + str(last_n_days))        \n",
    "    \n",
    "    df_melt = pd.merge(df_melt, rolling_stats_df, on = [\"Page\", \"date\"])     \n",
    "    \n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_melt(train):\n",
    "    \n",
    "#     train_melt = pd.read_csv(\"train_feats.csv\")\n",
    "        \n",
    "#     Commented because these features are already generated\n",
    "    train_melt = pd.melt(pd.concat([train.Page, \n",
    "                                    train.iloc[:, -60:]],\n",
    "                                    axis = 1),\n",
    "                                    id_vars=['Page'], \n",
    "                                    var_name=\"date\", value_name=\"visits\")\n",
    "\n",
    "#     train_melt = get_long_stats(\"mean\", train, train_melt, 7)\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"mean\", train, train_melt, 60)\n",
    "\n",
    "#     train_melt = get_long_stats(\"median\", train, train_melt, 7)\n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"median\", train, train_melt, 60)\n",
    "\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"std\", train, train_melt, 60)\n",
    "\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"min\", train, train_melt, 60)\n",
    "\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, 30)\n",
    "    train_melt = get_long_stats(\"max\", train, train_melt, 60)\n",
    "\n",
    "    train_melt = get_long_stats(\"mean_overall\", train, train_melt, 60)\n",
    "    train_melt = get_long_stats(\"median_overall\", train, train_melt, 60)\n",
    "    \n",
    "#     train_melt = get_long_stats(\"mean_diff\", train, train_melt, 7)\n",
    "#     train_melt = get_long_stats(\"last_day_visits\", train, train_melt)\n",
    "    \n",
    "    train_melt[\"date_num\"] = train_melt.apply(get_date, axis = 1)\n",
    "    train_melt[\"weekday\"] = train_melt.apply(get_weekday, axis = 1)\n",
    "    \n",
    "    # Columns i am not using\n",
    "    # train_melt[\"month\"] = train_melt.progress_apply(get_month, axis = 1)\n",
    "\n",
    "    return train_melt \n",
    "\n",
    "def get_lang_features(train_melt):\n",
    "    \n",
    "    train_melt = pd.merge(train_melt, pd.concat([train.Page, train.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    train_melt.columns = ['Page', 'date', 'visits', 'mean_30', 'mean_60', 'median_30', 'median_60', 'date_num', 'weekday', \"language\"]\n",
    "    \n",
    "    lang_date_melt = train_melt[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]\n",
    "        \n",
    "    train_melt = pd.merge(train_melt, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return train_melt\n",
    "\n",
    "train_melt = generate_train_melt(train)\n",
    "train_melt = get_lang_features(train_melt)\n",
    "train_melt.to_csv(\"train_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_source(row):\n",
    "    return row.Page.split[\".\"][-1].split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language(row):\n",
    "    try:\n",
    "        return row.Page.split(\".\")[0].split(\"_\")[-1]    \n",
    "    except:\n",
    "        return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_month(row):\n",
    "    return row.date.split(\"-\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(row):\n",
    "    return row.date.split(\"-\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weekday(row):\n",
    "    return datetime.datetime.strptime(row.date, '%Y-%m-%d').date().weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_language_mean(row):\n",
    "# lang_count = pd.Series(train_melt.groupby([\"language\"])[\"Page\"].count()).sort_values(axis = 0, ascending = False)\n",
    "# print lang_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_test(row, last_index, last_n_days, pred_index):\n",
    "    \n",
    "    start_loc = max(min(last_index - last_n_days, pred_index), 0)\n",
    "    end_loc = min(last_index, pred_index)\n",
    "\n",
    "    if start_loc < end_loc:\n",
    "        return np.median(row.iloc[ start_loc : end_loc ].tolist())\n",
    "    else:\n",
    "        return np.median(row.iloc[ pred_index - last_n_days : pred_index ].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_test(row, last_index, last_n_days, pred_index):\n",
    "    \n",
    "    start_loc = max(min(last_index - last_n_days, pred_index), 0)\n",
    "    end_loc = min(last_index, pred_index)\n",
    "    \n",
    "    if start_loc < end_loc:\n",
    "        return np.mean(row.iloc[start_loc : end_loc].tolist())\n",
    "    else:\n",
    "        return np.mean(row.iloc[pred_index - last_n_days : pred_index].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_diff_test(row, last_index):\n",
    "    \n",
    "    start_loc = min(last_index - 7, 61)\n",
    "    end_loc = min(last_index, 61)\n",
    "    \n",
    "    if start_loc < end_loc:\n",
    "        return np.mean([int(x) for x in np.diff( row.iloc[start_loc : end_loc] ) ], dtype=None)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lang_features_test(test_df):\n",
    "    \n",
    "    test_df = pd.merge(test_df, pd.concat([overall_df.Page, overall_df.progress_apply(get_language, axis = 1)], axis = 1), on = \"Page\")\n",
    "    test_df.columns = ['Page', 'date', 'mean_30', 'mean_60', 'median_30', 'median_60', 'date_num', 'weekday', \"language\"]\n",
    "    \n",
    "    lang_date_melt = test_df[[\"language\", \"date\", \"mean_30\", \"mean_60\", \"median_30\", \"median_60\"]]\n",
    "    \n",
    "    lang_feats = pd.DataFrame(lang_date_melt.groupby([\"language\", \"date\"], as_index = False).aggregate(np.mean))\n",
    "    lang_feats.columns = [\"language\", \"date\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]\n",
    "        \n",
    "    test_df = pd.merge(test_df, lang_feats, on = [\"language\", \"date\"])\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_last_day_visits_test(row, last_index):\n",
    "    \n",
    "    return row.iloc[last_index - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "        \n",
    "    y_true = y_true.get_label()\n",
    "    y_pred = np.array(y_pred)\n",
    "        \n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "\n",
    "    return \"smape\", np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(train, label_train, valid = None, label_valid = None):\n",
    "\n",
    "    # Set our parameters for xgboost\n",
    "    params = {}\n",
    "    params['objective'] = 'reg:linear'\n",
    "    params['eta'] = 0.05\n",
    "    params['max_depth'] = 7\n",
    "    params['silent'] = 1\n",
    "    params['min_child_weight'] = 0\n",
    "    params['subsample'] = 1\n",
    "    params['colsample_bytree'] = 1\n",
    "    params['nthread'] = 13\n",
    "    params['gamma'] = 0\n",
    "    params['max_delta_step'] = 0\n",
    "    \n",
    "    d_train = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    if valid is not None:\n",
    "        d_valid = xgb.DMatrix(valid, label=label_valid)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'validation')]\n",
    "    else:\n",
    "        watchlist = [(d_train, 'train')]\n",
    "        \n",
    "    bst = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=10, verbose_eval=10, feval=smape, maximize = False)\n",
    "\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_train_melt = np.log1p(train_melt[\"visits\"])\n",
    "label_train_melt = train_melt[\"visits\"]\n",
    "# label_train_melt = boxcox(np.array(label_train_melt), lmbda=0.094) #lambda found from default boxcox on outlier-stripped data\n",
    "\n",
    "# label_train_melt = [0] + np.diff(train_melt[\"visits\"]).tolist()\n",
    "\n",
    "train_melt.drop(\"visits\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"date\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"language\", axis = 1, inplace = True)\n",
    "train_melt.drop(\"Page\", axis = 1, inplace = True)\n",
    "\n",
    "# train_melt.drop(\"last_day_visits_None\", axis = 1, inplace = True)\n",
    "# train_melt.drop(\"mean_diff_7\", axis = 1, inplace = True)\n",
    "\n",
    "# train_melt.drop(\"mean_7\", axis = 1, inplace = True)\n",
    "# train_melt.drop(\"median_7\", axis = 1, inplace = True)\n",
    "\n",
    "train_melt.date_num = pd.to_numeric(train_melt.date_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:79662.7\tvalidation-rmse:85755.5\ttrain-smape:155.679\tvalidation-smape:153.177\n",
      "Multiple eval metrics have been passed: 'validation-smape' will be used for early stopping.\n",
      "\n",
      "Will train until validation-smape hasn't improved in 10 rounds.\n",
      "[10]\ttrain-rmse:77948.6\tvalidation-rmse:83552.2\ttrain-smape:85.5988\tvalidation-smape:85.9954\n",
      "[20]\ttrain-rmse:77176.4\tvalidation-rmse:82580.4\ttrain-smape:71.5804\tvalidation-smape:71.5424\n",
      "[30]\ttrain-rmse:76809.7\tvalidation-rmse:82141.1\ttrain-smape:64.8658\tvalidation-smape:64.9209\n",
      "[40]\ttrain-rmse:76629.9\tvalidation-rmse:81948.3\ttrain-smape:61.1142\tvalidation-smape:61.5857\n",
      "[50]\ttrain-rmse:76539.6\tvalidation-rmse:81873.6\ttrain-smape:59.3297\tvalidation-smape:59.6355\n",
      "[60]\ttrain-rmse:76481.4\tvalidation-rmse:81829.9\ttrain-smape:58.9017\tvalidation-smape:59.3542\n",
      "Stopping. Best iteration:\n",
      "[55]\ttrain-rmse:76505\tvalidation-rmse:81846.7\ttrain-smape:57.7275\tvalidation-smape:58.1065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, label_train, label_valid = train_test_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "bst = run_xgb(x_train, label_train, x_valid, label_valid)\n",
    "\n",
    "# bst = run_xgb(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature    fscore\n",
      "0             date_num  0.017921\n",
      "1              weekday  0.033154\n",
      "2  lang_median_60_mean  0.040323\n",
      "3    lang_mean_30_mean  0.059140\n",
      "4    lang_mean_60_mean  0.063620\n",
      "5              mean_60  0.071685\n",
      "6  lang_median_30_mean  0.083333\n",
      "7            median_60  0.133513\n",
      "8            median_30  0.198029\n",
      "9              mean_30  0.299283\n"
     ]
    }
   ],
   "source": [
    "importance = bst.get_fscore()\n",
    "\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df_imp = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df_imp['fscore'] = df_imp['fscore']/df_imp['fscore'].sum()\n",
    "\n",
    "print df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# x_train, x_valid, label_train, label_valid = train_test_split(train_melt, label_train_melt, test_size=0.2, random_state=4242)\n",
    "# # x_train = x_train.fillna(0)\n",
    "# # x_valid = x_valid.fillna(0)\n",
    "# reg.fit(x_train, label_train)\n",
    "\n",
    "reg.fit(train_melt, label_train_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction = reg.predict(x_valid)\n",
    "prediction = reg.predict(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.106730814\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(label_valid)\n",
    "y_pred = np.array(prediction)\n",
    "\n",
    "denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "diff = np.abs(y_true - y_pred) / denominator\n",
    "diff[denominator == 0] = 0.0\n",
    "\n",
    "print np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(test_df):\n",
    "    \n",
    "    d_test = xgb.DMatrix(test_df)\n",
    "    p_test = bst.predict(d_test)\n",
    "    \n",
    "    return pd.Series(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overall_df():\n",
    "    \n",
    "    key_wide = pd.DataFrame()\n",
    "    key_wide[\"page\"] = np.unique(key.trunc_page).tolist()\n",
    "    for i in np.unique(key.date).tolist():\n",
    "        key_wide[i] = 0\n",
    "\n",
    "    overall_df = pd.merge(train, key_wide, left_on=\"Page\", right_on = \"page\", how = \"inner\")\n",
    "    overall_df.drop(\"page\", axis = 1, inplace = True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_df(overall_df):\n",
    "    \n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    pred_index = overall_df.columns.tolist().index('2017-01-01')\n",
    "    \n",
    "    for i in range(pred_index, len(overall_df.columns)):\n",
    "\n",
    "        last_date = overall_df.columns.tolist()[i]\n",
    "        print last_date\n",
    "        last_index = i\n",
    "\n",
    "        test_feats = pd.DataFrame()\n",
    "        \n",
    "        test_feats[\"Page\"] = overall_df.Page\n",
    "        test_feats[\"date\"] = last_date\n",
    "        \n",
    "#         test_feats[\"mean_7\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 7, pred_index = pred_index)\n",
    "        test_feats[\"mean_30\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 30, pred_index = pred_index)\n",
    "        test_feats[\"mean_60\"] = overall_df.apply(get_mean_test, axis = 1, last_index = last_index, last_n_days = 60, pred_index = pred_index)\n",
    "\n",
    "#         test_feats[\"median_7\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 7, pred_index = pred_index)\n",
    "        test_feats[\"median_30\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 30, pred_index = pred_index)\n",
    "        test_feats[\"median_60\"] = overall_df.apply(get_median_test, axis = 1, last_index = last_index, last_n_days = 60, pred_index = pred_index)\n",
    "\n",
    "#         test_feats[\"mean_diff_7\"] = overall_df.apply(get_mean_diff_test, axis = 1, last_index = last_index)\n",
    "#         test_feats[\"last_day_visits_None\"] = overall_df.apply(get_last_day_visits_test, axis = 1, last_index = last_index)\n",
    "\n",
    "#         test_feats[\"month\"] = last_date.split(\"-\")[1]\n",
    "        test_feats[\"date_num\"] = pd.to_numeric(last_date.split(\"-\")[2])\n",
    "        test_feats[\"weekday\"] = datetime.datetime.strptime(last_date, '%Y-%m-%d').date().weekday()\n",
    "                                \n",
    "        test_df = pd.concat([test_df, test_feats])\n",
    "        \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = get_overall_df()\n",
    "test_df = get_test_df(overall_df)\n",
    "test_df = get_lang_features_test(test_df)\n",
    "test_df.to_csv(\"test_feats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_feats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = get_preds(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\", \"lang_mean_30_mean\", \"lang_mean_60_mean\", \"lang_median_30_mean\", \"lang_median_60_mean\"]])\n",
    "\n",
    "# prediction = invboxcox(get_preds(test_df[[\"mean_30\",\"mean_60\",\"median_30\",\"median_60\",\"date_num\", \"weekday\"]]), ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_index = overall_df.columns.tolist().index(\"2017-01-01\")\n",
    "\n",
    "# pred_df = overall_df.iloc[:, pred_index:]\n",
    "# pred_df[\"Page\"] = overall_df.Page\n",
    "\n",
    "# pred_df_melt = pd.melt(pred_df, id_vars=['Page'], var_name=\"date\", value_name=\"Visits\")        \n",
    "\n",
    "test_df[\"Visits\"] = prediction\n",
    "# pred_df = pd.concat([test_df[[\"Page\", \"date\"]], prediction], axis = 1)\n",
    "pred_df = test_df[[\"Page\", \"date\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits = pd.merge(pred_df, key, left_on=[\"Page\", \"date\"], right_on=[\"trunc_page\", \"date\"], how=\"inner\")[[\"Id\", \"Visits\"]]\n",
    "\n",
    "pred_id_visits.to_csv(\"pred_glm_3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/stats/morestats.py:516: RuntimeWarning: divide by zero encountered in log\n",
      "  y = where(lmbda == 0, log(x), (x**lmbda - 1)/lmbda)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import *\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt if i > 4 and i < 1871])) #Outlier 10% to 90% only\n",
    "# bc_label, lambda_val = boxcox(np.array([i for i in label_train_melt]))\n",
    "\n",
    "bc_label = boxcox(np.array(label_train_melt), lmbda=0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invboxcox(y,ld):\n",
    "    if ld == 0:\n",
    "        return(np.exp(y))\n",
    "    else:\n",
    "        return(np.exp(np.log(ld*y+1)/ld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.,  11.,   3., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.percentile(label_train_melt, 90)\n",
    "# np.percentile(label_train_melt, 10)\n",
    "# len([i for i in label_train_melt if i > 4 and i < 1871])\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(bc_label.tolist())\n",
    "# plt.show()\n",
    "\n",
    "# bc_label\n",
    "\n",
    "# import scipy.special.inv_boxcox\n",
    "invboxcox(bc_label, ld = 0.094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>2015-07-01</th>\n",
       "      <th>2015-07-02</th>\n",
       "      <th>2015-07-03</th>\n",
       "      <th>2015-07-04</th>\n",
       "      <th>2015-07-05</th>\n",
       "      <th>2015-07-06</th>\n",
       "      <th>2015-07-07</th>\n",
       "      <th>2015-07-08</th>\n",
       "      <th>2015-07-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-12-22</th>\n",
       "      <th>2016-12-23</th>\n",
       "      <th>2016-12-24</th>\n",
       "      <th>2016-12-25</th>\n",
       "      <th>2016-12-26</th>\n",
       "      <th>2016-12-27</th>\n",
       "      <th>2016-12-28</th>\n",
       "      <th>2016-12-29</th>\n",
       "      <th>2016-12-30</th>\n",
       "      <th>2016-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2NE1_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2PM_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3C_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4minute_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Page  2015-07-01  2015-07-02  \\\n",
       "0            2NE1_zh.wikipedia.org_all-access_spider        18.0        11.0   \n",
       "1             2PM_zh.wikipedia.org_all-access_spider        11.0        14.0   \n",
       "2              3C_zh.wikipedia.org_all-access_spider         1.0         0.0   \n",
       "3         4minute_zh.wikipedia.org_all-access_spider        35.0        13.0   \n",
       "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...         0.0         0.0   \n",
       "\n",
       "   2015-07-03  2015-07-04  2015-07-05  2015-07-06  2015-07-07  2015-07-08  \\\n",
       "0         5.0        13.0        14.0         9.0         9.0        22.0   \n",
       "1        15.0        18.0        11.0        13.0        22.0        11.0   \n",
       "2         1.0         1.0         0.0         4.0         0.0         3.0   \n",
       "3        10.0        94.0         4.0        26.0        14.0         9.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2015-07-09     ...      2016-12-22  2016-12-23  2016-12-24  2016-12-25  \\\n",
       "0        26.0     ...            32.0        63.0        15.0        26.0   \n",
       "1        10.0     ...            17.0        42.0        28.0        15.0   \n",
       "2         4.0     ...             3.0         1.0         1.0         7.0   \n",
       "3        11.0     ...            32.0        10.0        26.0        27.0   \n",
       "4         0.0     ...            48.0         9.0        25.0        13.0   \n",
       "\n",
       "   2016-12-26  2016-12-27  2016-12-28  2016-12-29  2016-12-30  2016-12-31  \n",
       "0        14.0        20.0        22.0        19.0        18.0        20.0  \n",
       "1         9.0        30.0        52.0        45.0        26.0        20.0  \n",
       "2         4.0         4.0         6.0         3.0         4.0        17.0  \n",
       "3        16.0        11.0        17.0        19.0        10.0        11.0  \n",
       "4         3.0        11.0        27.0        13.0        36.0        10.0  \n",
       "\n",
       "[5 rows x 551 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
